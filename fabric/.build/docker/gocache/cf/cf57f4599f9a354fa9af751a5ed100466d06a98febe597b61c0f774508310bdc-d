// Code generated by cmd/cgo; DO NOT EDIT.

//line /opt/gopath/src/github.com/hyperledger/fabric/vendor/github.com/DataDog/zstd/zstd_stream.go:1:1
package zstd

/*
#define ZSTD_STATIC_LINKING_ONLY
#define ZBUFF_DISABLE_DEPRECATE_WARNINGS
#include "zstd.h"
#include "zbuff.h"
*/
import _ "unsafe"
import (
	"errors"
	"fmt"
	"io"
	"runtime"
	"unsafe"
)

var errShortRead = errors.New("short read")

// Writer is an io.WriteCloser that zstd-compresses its input.
type Writer struct {
	CompressionLevel int

	ctx              * /*line :24:20*/_Ctype_struct_ZSTD_CCtx_s /*line :24:31*/
	dict             []byte
	dstBuffer        []byte
	firstError       error
	underlyingWriter io.Writer
}

func resize(in []byte, newSize int) []byte {
	if in == nil {
		return make([]byte, newSize)
	}
	if newSize <= cap(in) {
		return in[:newSize]
	}
	toAdd := newSize - len(in)
	return append(in, make([]byte, toAdd)...)
}

// NewWriter creates a new Writer with default compression options.  Writes to
// the writer will be written in compressed form to w.
func NewWriter(w io.Writer) *Writer {
	return NewWriterLevelDict(w, DefaultCompression, nil)
}

// NewWriterLevel is like NewWriter but specifies the compression level instead
// of assuming default compression.
//
// The level can be DefaultCompression or any integer value between BestSpeed
// and BestCompression inclusive.
func NewWriterLevel(w io.Writer, level int) *Writer {
	return NewWriterLevelDict(w, level, nil)

}

// NewWriterLevelDict is like NewWriterLevel but specifies a dictionary to
// compress with.  If the dictionary is empty or nil it is ignored. The dictionary
// should not be modified until the writer is closed.
func NewWriterLevelDict(w io.Writer, level int, dict []byte) *Writer {
	var err error
	ctx := ( /*line :63:9*/_Cfunc_ZSTD_createCCtx /*line :63:25*/)()

	if dict == nil {
		err = getError(int(func() _Ctype_size_t{ _cgo0 := /*line :66:43*/ctx; var _cgo1 _Ctype_int = _Ctype_int(level); _cgoCheckPointer(_cgo0, nil); return _Cfunc_ZSTD_compressBegin(_cgo0, _cgo1); }()))
	} else {
		err = getError(int(func() _Ctype_size_t{ _cgo0 := /*line :70:4*/ctx; _cgoIndex1 := &/*line :71:20*/dict; _cgo1 := /*line :71:4*/unsafe.Pointer(&(*_cgoIndex1)[0]); var _cgo2 _Ctype_size_t = _Ctype_size_t(len(dict)); var _cgo3 _Ctype_int = _Ctype_int(level); _cgoCheckPointer(_cgo0, nil); _cgoCheckPointer(_cgo1, *_cgoIndex1); return _Cfunc_ZSTD_compressBegin_usingDict(_cgo0, _cgo1, _cgo2, _cgo3); }()))
	}

	return &Writer{
		CompressionLevel: level,
		ctx:              ctx,
		dict:             dict,
		dstBuffer:        make([]byte, CompressBound(1024)),
		firstError:       err,
		underlyingWriter: w,
	}
}

// Write writes a compressed form of p to the underlying io.Writer.
func (w *Writer) Write(p []byte) (int, error) {
	if w.firstError != nil {
		return 0, w.firstError
	}
	if len(p) == 0 {
		return 0, nil
	}
	// Check if dstBuffer is enough
	if len(w.dstBuffer) < CompressBound(len(p)) {
		w.dstBuffer = make([]byte, CompressBound(len(p)))
	}

	retCode := func() _Ctype_size_t{ _cgo0 := /*line :100:3*/w.ctx; _cgoIndex1 := &/*line :101:19*/w.dstBuffer; _cgo1 := /*line :101:3*/unsafe.Pointer(&(*_cgoIndex1)[0]); var _cgo2 _Ctype_size_t = _Ctype_size_t(len(w.dstBuffer)); _cgoIndex3 := &/*line :103:19*/p; _cgo3 := /*line :103:3*/unsafe.Pointer(&(*_cgoIndex3)[0]); var _cgo4 _Ctype_size_t = _Ctype_size_t(len(p)); _cgoCheckPointer(_cgo0, nil); _cgoCheckPointer(_cgo1, *_cgoIndex1); _cgoCheckPointer(_cgo3, *_cgoIndex3); return _Cfunc_ZSTD_compressContinue(_cgo0, _cgo1, _cgo2, _cgo3, _cgo4); }()

	if err := getError(int(retCode)); err != nil {
		return 0, err
	}
	written := int(retCode)

	// Write to underlying buffer
	_, err := w.underlyingWriter.Write(w.dstBuffer[:written])

	// Same behaviour as zlib, we can't know how much data we wrote, only
	// if there was an error
	if err != nil {
		return 0, err
	}
	return len(p), err
}

// Close closes the Writer, flushing any unwritten data to the underlying
// io.Writer and freeing objects, but does not close the underlying io.Writer.
func (w *Writer) Close() error {
	retCode := func() _Ctype_size_t{ _cgo0 := /*line :126:3*/w.ctx; _cgoIndex1 := &/*line :127:19*/w.dstBuffer; _cgo1 := /*line :127:3*/unsafe.Pointer(&(*_cgoIndex1)[0]); var _cgo2 _Ctype_size_t = _Ctype_size_t(len(w.dstBuffer)); _cgo3 := /*line :129:3*/unsafe.Pointer(nil); var _cgo4 _Ctype_size_t = _Ctype_size_t(0); _cgoCheckPointer(_cgo0, nil); _cgoCheckPointer(_cgo1, *_cgoIndex1); _cgoCheckPointer(_cgo3, nil); return _Cfunc_ZSTD_compressEnd(_cgo0, _cgo1, _cgo2, _cgo3, _cgo4); }()

	if err := getError(int(retCode)); err != nil {
		return err
	}
	written := int(retCode)
	retCode = func() _Ctype_size_t{ _cgo0 := /*line :136:28*/w.ctx; _cgoCheckPointer(_cgo0, nil); return _Cfunc_ZSTD_freeCCtx(_cgo0); }() // Safely close buffer before writing the end

	if err := getError(int(retCode)); err != nil {
		return err
	}

	_, err := w.underlyingWriter.Write(w.dstBuffer[:written])
	if err != nil {
		return err
	}
	return nil
}

// reader is an io.ReadCloser that decompresses when read from.
type reader struct {
	ctx                 * /*line :151:23*/_Ctype_struct_ZSTD_DCtx_s /*line :151:35*/
	compressionBuffer   []byte
	compressionLeft     int
	decompressionBuffer []byte
	decompOff           int
	decompSize          int
	dict                []byte
	firstError          error
	recommendedSrcSize  int
	underlyingReader    io.Reader
}

// NewReader creates a new io.ReadCloser.  Reads from the returned ReadCloser
// read and decompress data from r.  It is the caller's responsibility to call
// Close on the ReadCloser when done.  If this is not done, underlying objects
// in the zstd library will not be freed.
func NewReader(r io.Reader) io.ReadCloser {
	return NewReaderDict(r, nil)
}

// NewReaderDict is like NewReader but uses a preset dictionary.  NewReaderDict
// ignores the dictionary if it is nil.
func NewReaderDict(r io.Reader, dict []byte) io.ReadCloser {
	var err error
	ctx := ( /*line :175:9*/_Cfunc_ZBUFF_createDCtx /*line :175:26*/)()
	if len(dict) == 0 {
		err = getError(int(func() _Ctype_size_t{ _cgo0 := /*line :177:45*/ctx; _cgoCheckPointer(_cgo0, nil); return _Cfunc_ZBUFF_decompressInit(_cgo0); }()))
	} else {
		err = getError(int(func() _Ctype_size_t{ _cgo0 := /*line :180:4*/ctx; _cgoIndex1 := &/*line :181:20*/dict; _cgo1 := /*line :181:4*/unsafe.Pointer(&(*_cgoIndex1)[0]); var _cgo2 _Ctype_size_t = _Ctype_size_t(len(dict)); _cgoCheckPointer(_cgo0, nil); _cgoCheckPointer(_cgo1, *_cgoIndex1); return _Cfunc_ZBUFF_decompressInitDictionary(_cgo0, _cgo1, _cgo2); }()))
	}
	cSize := int(( /*line :184:15*/_Cfunc_ZBUFF_recommendedDInSize /*line :184:40*/)())
	dSize := int(( /*line :185:15*/_Cfunc_ZBUFF_recommendedDOutSize /*line :185:41*/)())
	if cSize <= 0 {
		panic(fmt.Errorf("ZBUFF_recommendedDInSize() returned invalid size: %v", cSize))
	}
	if dSize <= 0 {
		panic(fmt.Errorf("ZBUFF_recommendedDOutSize() returned invalid size: %v", dSize))
	}

	compressionBuffer := make([]byte, cSize)
	decompressionBuffer := make([]byte, dSize)
	return &reader{
		ctx:                 ctx,
		dict:                dict,
		compressionBuffer:   compressionBuffer,
		decompressionBuffer: decompressionBuffer,
		firstError:          err,
		recommendedSrcSize:  cSize,
		underlyingReader:    r,
	}
}

// Close frees the allocated C objects
func (r *reader) Close() error {
	return getError(int(func() _Ctype_size_t{ _cgo0 := /*line :208:39*/r.ctx; _cgoCheckPointer(_cgo0, nil); return _Cfunc_ZBUFF_freeDCtx(_cgo0); }()))
}

func (r *reader) Read(p []byte) (int, error) {

	// If we already have enough bytes, return
	if r.decompSize-r.decompOff >= len(p) {
		copy(p, r.decompressionBuffer[r.decompOff:])
		r.decompOff += len(p)
		return len(p), nil
	}

	copy(p, r.decompressionBuffer[r.decompOff:r.decompSize])
	got := r.decompSize - r.decompOff
	r.decompSize = 0
	r.decompOff = 0

	for got < len(p) {
		// Populate src
		src := r.compressionBuffer
		reader := r.underlyingReader
		n, err := TryReadFull(reader, src[r.compressionLeft:])
		if err != nil && err != errShortRead { // Handle underlying reader errors first
			return 0, fmt.Errorf("failed to read from underlying reader: %s", err)
		} else if n == 0 && r.compressionLeft == 0 {
			return got, io.EOF
		}
		src = src[:r.compressionLeft+n]

		// C code
		cSrcSize :=  /*line :238:15*/_Ctype_size_t /*line :238:23*/(len(src))
		cDstSize :=  /*line :239:15*/_Ctype_size_t /*line :239:23*/(len(r.decompressionBuffer))
		retCode := int(func() _Ctype_size_t{ _cgo0 := /*line :241:4*/r.ctx; _cgoIndex1 := &/*line :242:20*/r.decompressionBuffer; _cgo1 := /*line :242:4*/unsafe.Pointer(&(*_cgoIndex1)[0]); var _cgo2 *_Ctype_size_t = /*line :243:4*/&cDstSize; _cgoIndex3 := &/*line :244:20*/src; _cgo3 := /*line :244:4*/unsafe.Pointer(&(*_cgoIndex3)[0]); var _cgo4 *_Ctype_size_t = /*line :245:4*/&cSrcSize; _cgoCheckPointer(_cgo0, nil); _cgoCheckPointer(_cgo1, *_cgoIndex1); _cgoCheckPointer(_cgo3, *_cgoIndex3); return _Cfunc_ZBUFF_decompressContinue(_cgo0, _cgo1, _cgo2, _cgo3, _cgo4); }())

		// Keep src here eventhough, we reuse later, the code might be deleted at some point
		runtime.KeepAlive(src)
		if err = getError(retCode); err != nil {
			return 0, fmt.Errorf("failed to decompress: %s", err)
		}

		// Put everything in buffer
		if int(cSrcSize) < len(src) {
			left := src[int(cSrcSize):]
			copy(r.compressionBuffer, left)
		}
		r.compressionLeft = len(src) - int(cSrcSize)
		r.decompSize = int(cDstSize)
		r.decompOff = copy(p[got:], r.decompressionBuffer[:r.decompSize])
		got += r.decompOff

		// Resize buffers
		nsize := retCode // Hint for next src buffer size
		if nsize <= 0 {
			// Reset to recommended size
			nsize = r.recommendedSrcSize
		}
		if nsize < r.compressionLeft {
			nsize = r.compressionLeft
		}
		r.compressionBuffer = resize(r.compressionBuffer, nsize)
	}
	return got, nil
}

// TryReadFull reads buffer just as ReadFull does
// Here we expect that buffer may end and we do not return ErrUnexpectedEOF as ReadAtLeast does.
// We return errShortRead instead to distinguish short reads and failures.
// We cannot use ReadFull/ReadAtLeast because it masks Reader errors, such as network failures
// and causes panic instead of error.
func TryReadFull(r io.Reader, buf []byte) (n int, err error) {
	for n < len(buf) && err == nil {
		var nn int
		nn, err = r.Read(buf[n:])
		n += nn
	}
	if n == len(buf) && err == io.EOF {
		err = nil // EOF at the end is somewhat expected
	} else if err == io.EOF {
		err = errShortRead
	}
	return
}
